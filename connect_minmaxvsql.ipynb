{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_board(rows, columns):\n",
    "    return np.zeros((rows, columns))\n",
    "\n",
    "def val_turn(c4_board, column):\n",
    "    return c4_board[len(c4_board)-1][column] == 0\n",
    "\n",
    "def get_next_row(c4_board, column):\n",
    "    return next((row for row in range(len(c4_board)) if c4_board[row][column] == 0), None)\n",
    "\n",
    "def get_allowed_moves(c4_board):\n",
    "    return [column for column in range(c4_board.shape[1]) if val_turn(c4_board, column)]\n",
    "\n",
    "def get_next_position(c4_board, letter):\n",
    "    rows, cols = c4_board.shape\n",
    "    for row, row_vals in enumerate(c4_board):\n",
    "        for col, col_val in enumerate(row_vals[:-3]):\n",
    "            if all(elem == letter for elem in row_vals[col:col+4]):\n",
    "                return row, col\n",
    "        for col, col_vals in zip(range(cols), (c4_board[r][col] for r in range(row, min(row+4, rows)))):\n",
    "            if all(elem == letter for elem in col_vals):\n",
    "                return row, col\n",
    "        for col, col_vals in enumerate(row_vals[:-3]):\n",
    "            if row < rows-3 and col < cols-3:\n",
    "                diag_vals = [c4_board[row+i][col+i] for i in range(4)]\n",
    "                if all(elem == letter for elem in diag_vals):\n",
    "                    return row, col\n",
    "        for col, col_vals in enumerate(row_vals[:-3]):\n",
    "            if row >= 3 and col < cols-3:\n",
    "                diag_vals = [c4_board[row-i][col+i] for i in range(4)]\n",
    "                if all(elem == letter for elem in diag_vals):\n",
    "                    return row, col\n",
    "    return -1, -1\n",
    "\n",
    "def val_success(c4_board, letter):\n",
    "    rows, columns = c4_board.shape\n",
    "    for row in range(rows):\n",
    "        for col in range(columns - 3):\n",
    "            if all(c4_board[row][col + i] == letter for i in range(4)):\n",
    "                return True\n",
    "\n",
    "    for row in range(rows - 3):\n",
    "        for col in range(columns):\n",
    "            if all(c4_board[row + i][col] == letter for i in range(4)):\n",
    "                return True\n",
    "\n",
    "    for row in range(rows - 3):\n",
    "        for col in range(columns - 3):\n",
    "            if all(c4_board[row + i][col + i] == letter for i in range(4)):\n",
    "                return True\n",
    "\n",
    "    for row in range(3, rows):\n",
    "        for col in range(columns - 3):\n",
    "            if all(c4_board[row - i][col + i] == letter for i in range(4)):\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def first_turn_toss():\n",
    "    choices = [1,2]\n",
    "    return random.choice(choices)\n",
    "\n",
    "def val_final_turn(c4_board, SI_Agent_Letter, MinMax_Letter):\n",
    "    return any(val_success(c4_board, letter) for letter in (SI_Agent_Letter, MinMax_Letter)) or not get_allowed_moves(c4_board)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(positions):\n",
    "    return int(''.join([str(int(position)) for position in positions.flatten()]))\n",
    "\n",
    "def get_q_values_for_action(ql_states, current_board, current_position):\n",
    "    position = get_pos(current_board)\n",
    "    if position not in ql_states:\n",
    "        ql_states[(position, current_position)] = 0\n",
    "    return ql_states[(position, current_position)]\n",
    "\n",
    "def get_best_action_from_q_values(ql_states, current_board, possible_positions, epsilon):\n",
    "    return random.choice(possible_positions) if random.random() < epsilon else max([(get_q_values_for_action(ql_states, current_board, position), position) for position in possible_positions], key=lambda x: x[0])[1]\n",
    "\n",
    "def load_q_model(file_path=\"Connect4QLModel.pickle\"):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        ql_states = pickle.load(file)\n",
    "    return ql_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(c4_board, letter, SIAgentLetter, MinMaxLetter):\n",
    "    score = 0\n",
    "    OtherPlayerLetter = MinMaxLetter if letter == SIAgentLetter else SIAgentLetter\n",
    "    rows, cols = c4_board.shape\n",
    "\n",
    "    for i in range(rows):\n",
    "        row_array = [int(x) for x in list(c4_board[i,:])]\n",
    "        col_array = [int(x) for x in list(c4_board[:,i])]\n",
    "        for j in range(cols-3):\n",
    "            sub_row = row_array[j:j+4]\n",
    "            sub_col = col_array[j:j+4]\n",
    "            if sub_row.count(letter) == 4:\n",
    "                score += 1000\n",
    "            elif sub_row.count(letter) == 3 and sub_row.count(0) == 1:\n",
    "                score += 100\n",
    "            elif sub_row.count(letter) == 2 and sub_row.count(0) == 2:\n",
    "                score += 10\n",
    "            if sub_row.count(OtherPlayerLetter) == 3 and sub_row.count(0) == 1:\n",
    "                score -= 10\n",
    "            if sub_col.count(letter) == 4:\n",
    "                score += 1000\n",
    "            elif sub_col.count(letter) == 3 and sub_col.count(0) == 1:\n",
    "                score += 100\n",
    "            elif sub_col.count(letter) == 2 and sub_col.count(0) == 2:\n",
    "                score += 10\n",
    "            if sub_col.count(OtherPlayerLetter) == 3 and sub_col.count(0) == 1:\n",
    "                score -= 10\n",
    "\n",
    "    for i in range(rows-3):\n",
    "        for j in range(cols-3):\n",
    "            sub_diagonal1 = [c4_board[i+k][j+k] for k in range(4)]\n",
    "            sub_diagonal2 = [c4_board[i+3-k][j+k] for k in range(4)]\n",
    "            if sub_diagonal1.count(letter) == 4:\n",
    "                score += 1000\n",
    "            elif sub_diagonal1.count(letter) == 3 and sub_diagonal1.count(0) == 1:\n",
    "                score += 100\n",
    "            elif sub_diagonal1.count(letter) == 2 and sub_diagonal1.count(0) == 2:\n",
    "                score += 10\n",
    "            if sub_diagonal1.count(OtherPlayerLetter) == 3 and sub_diagonal1.count(0) == 1:\n",
    "                score -= 10\n",
    "            if sub_diagonal2.count(letter) == 4:\n",
    "                score += 1000\n",
    "            elif sub_diagonal2.count(letter) == 3 and sub_diagonal2.count(0) == 1:\n",
    "                score += 100\n",
    "            elif sub_diagonal2.count(letter) == 2 and sub_diagonal2.count(0) == 2:\n",
    "                score += 10\n",
    "            if sub_diagonal2.count(OtherPlayerLetter) == 3 and sub_diagonal2.count(0) == 1:\n",
    "                score -= 10\n",
    "\n",
    "    return score\n",
    "\n",
    "def min_max_with_alpha_beta_pruning_and_depth(c4_board, current_depth, isMinMaxMove, MinMaxLetter, SIAgentLetter, alpha, beta):\n",
    "\n",
    "    if val_final_turn(c4_board, SIAgentLetter, MinMaxLetter):\n",
    "\n",
    "        if val_success(c4_board, MinMaxLetter):\n",
    "            return (None, 10000000)\n",
    "\n",
    "        elif val_success(c4_board, SIAgentLetter):\n",
    "            return (None, -10000000)\n",
    "\n",
    "        else:\n",
    "            return (None, 0)\n",
    "\n",
    "    if current_depth == 0:\n",
    "        return (None, calculate_score(c4_board, MinMaxLetter, SIAgentLetter, MinMaxLetter))\n",
    "\n",
    "    possible_positions = get_allowed_moves(c4_board)\n",
    "\n",
    "    if isMinMaxMove:\n",
    "        optimisedScore = -math.inf\n",
    "        optimisedPosition = random.choice(possible_positions)\n",
    "\n",
    "        for position in possible_positions:\n",
    "            random_row = get_next_row(c4_board, position)\n",
    "            new_c4_board = c4_board.copy()\n",
    "            new_c4_board[random_row][position] = MinMaxLetter\n",
    "            current_minmax_score = min_max_with_alpha_beta_pruning_and_depth(new_c4_board, current_depth - 1, False, MinMaxLetter, SIAgentLetter, alpha, beta)[1]\n",
    "\n",
    "            if current_minmax_score > optimisedScore:\n",
    "                optimisedScore = current_minmax_score\n",
    "                optimisedPosition = position\n",
    "\n",
    "            alpha = max(optimisedScore, alpha)\n",
    "\n",
    "            if alpha >= beta:\n",
    "                break\n",
    "\n",
    "        return optimisedPosition, optimisedScore\n",
    "\n",
    "    else:\n",
    "        optimisedScore = math.inf\n",
    "        optimisedPosition = random.choice(possible_positions)\n",
    "\n",
    "        for position in possible_positions:\n",
    "            random_row = get_next_row(c4_board, position)\n",
    "            new_c4_board = c4_board.copy()\n",
    "            new_c4_board[random_row][position] = MinMaxLetter\n",
    "            current_minmax_score = min_max_with_alpha_beta_pruning_and_depth(new_c4_board, current_depth - 1, True, MinMaxLetter, SIAgentLetter, alpha, beta)[1]\n",
    "\n",
    "            if current_minmax_score < optimisedScore:\n",
    "                optimisedScore = current_minmax_score\n",
    "                optimisedPosition = position\n",
    "\n",
    "            beta = min(beta, optimisedScore)\n",
    "\n",
    "            if alpha >= beta:\n",
    "                break\n",
    "\n",
    "        return optimisedPosition, optimisedScore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_connect4_game(MinMaxPlaysFirst, qLearningPlayer, minmaxPlayer, c4Game):\n",
    "    QLearningLetter = 1\n",
    "    MinMaxLetter = 2\n",
    "    \n",
    "    while True:\n",
    "        if MinMaxPlaysFirst:\n",
    "            MinMaxPossible_Positions = get_allowed_moves(c4Game)\n",
    "\n",
    "            if len(MinMaxPossible_Positions) == 0:\n",
    "                return \"Draw\"\n",
    "\n",
    "            minmax_chosen_column, _ = min_max_with_alpha_beta_pruning_and_depth(c4Game, 8, True, MinMaxLetter, QLearningLetter, -math.inf, math.inf)\n",
    "\n",
    "            minmax_chosen_row = get_next_row(c4Game, minmax_chosen_column)\n",
    "            c4Game[minmax_chosen_row][minmax_chosen_column] = MinMaxLetter\n",
    "\n",
    "            if val_success(c4Game, MinMaxLetter):\n",
    "                return \"MinMaxWon\"\n",
    "\n",
    "            if val_success(c4Game, QLearningLetter):\n",
    "                return \"QLearningWon\"\n",
    "\n",
    "            if len(get_allowed_moves(c4Game)) == 0:\n",
    "                return \"Draw\"\n",
    "\n",
    "            QLearningPossible_Positions = get_allowed_moves(c4Game)\n",
    "\n",
    "            if len(QLearningPossible_Positions) == 0:\n",
    "                return \"Draw\"\n",
    "\n",
    "            QLearning_chosen_column = get_best_action_from_q_values(qLearningPlayer, c4Game, QLearningPossible_Positions)\n",
    "            QLearning_chosen_row = get_next_row(c4Game, QLearning_chosen_column)\n",
    "            c4Game[QLearning_chosen_row][QLearning_chosen_column] = QLearningLetter\n",
    "\n",
    "            if val_success(c4Game, QLearningLetter):\n",
    "                return \"QLearningWon\"\n",
    "\n",
    "            if val_success(c4Game, MinMaxLetter):\n",
    "                return \"MinMaxWon\"\n",
    "\n",
    "            if len(get_allowed_moves(c4Game)) == 0:\n",
    "                return \"Draw\"\n",
    "        else:\n",
    "            QLearningPossible_Positions = get_allowed_moves(c4Game)\n",
    "\n",
    "            if len(QLearningPossible_Positions) == 0:\n",
    "                return \"Draw\"\n",
    "\n",
    "            QLearning_chosen_column = get_best_action_from_q_values(qLearningPlayer, c4Game, QLearningPossible_Positions,epsilon=1.0)\n",
    "            QLearning_chosen_row = get_next_row(c4Game, QLearning_chosen_column)\n",
    "            c4Game[QLearning_chosen_row][QLearning_chosen_column] = QLearningLetter\n",
    "\n",
    "            if val_success(c4Game, QLearningLetter):\n",
    "                return \"QLearningWon\"\n",
    "\n",
    "            if val_success(c4Game, MinMaxLetter):\n",
    "                return \"MinMaxWon\"\n",
    "\n",
    "            if len(get_allowed_moves(c4Game)) == 0:\n",
    "                return \"Draw\"\n",
    "\n",
    "            MinMaxPossible_Positions = get_allowed_moves(c4Game)\n",
    "\n",
    "            if len(MinMaxPossible_Positions) == 0:\n",
    "                return \"Draw\"\n",
    "\n",
    "            minmax_chosen_column, _ = min_max_with_alpha_beta_pruning_and_depth(c4Game, 8, True, MinMaxLetter, QLearningLetter, -math.inf, math.inf)\n",
    "\n",
    "            minmax_chosen_row = get_next_row(c4Game, minmax_chosen_column)\n",
    "            c4Game[minmax_chosen_row][minmax_chosen_column] = MinMaxLetter\n",
    "\n",
    "            if val_success(c4Game, MinMaxLetter):\n",
    "                return \"MinMaxWon\"\n",
    "\n",
    "            if val_success(c4Game, QLearningLetter):\n",
    "                return \"QLearningWon\"\n",
    "\n",
    "            if len(get_allowed_moves(c4Game)) == 0:\n",
    "                return \"Draw\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_connect4_game(MinMaxPlaysFirst, qLearningPlayer, MinMaxLetter, QLearningLetter, c4Game, depth=8, epsilon=0.1):\n",
    "    while True:\n",
    "        current_player_first = MinMaxPlaysFirst\n",
    "        for _ in range(2):  # Each loop actually allows both players to play once, order depends on MinMaxPlaysFirst\n",
    "            if current_player_first:\n",
    "                # MinMax's turn\n",
    "                possible_positions = get_allowed_moves(c4Game)\n",
    "                if not possible_positions:\n",
    "                    return \"Draw\"\n",
    "                chosen_column, _ = min_max_with_alpha_beta_pruning_and_depth(c4Game, depth, True, MinMaxLetter, QLearningLetter, -math.inf, math.inf)\n",
    "                chosen_row = get_next_row(c4Game, chosen_column)\n",
    "                c4Game[chosen_row][chosen_column] = MinMaxLetter\n",
    "                if val_success(c4Game, MinMaxLetter):\n",
    "                    return \"MinMaxWon\"\n",
    "            else:\n",
    "                # QLearning's turn\n",
    "                possible_positions = get_allowed_moves(c4Game)\n",
    "                if not possible_positions:\n",
    "                    return \"Draw\"\n",
    "                chosen_column = get_best_action_from_q_values(qLearningPlayer, c4Game, possible_positions, epsilon)\n",
    "                chosen_row = get_next_row(c4Game, chosen_column)\n",
    "                c4Game[chosen_row][chosen_column] = QLearningLetter\n",
    "                if val_success(c4Game, QLearningLetter):\n",
    "                    return \"QLearningWon\"\n",
    "            \n",
    "            # Switch players after each move\n",
    "            current_player_first = not current_player_first\n",
    "\n",
    "            # Check for draw after each move\n",
    "            if not get_allowed_moves(c4Game):\n",
    "                return \"Draw\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fisrt is Random Move between MinMax and Qlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Q Learning model has 87890237 states\n",
      "Results:\n",
      "MinMax wins: 3\n",
      "QLearning wins: 1\n",
      "Draws: 1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def simulate_games(games, rows, columns):\n",
    "    MinMaxWin = QLearningWin = Draw = 0\n",
    "    qLearningPlayer = load_q_model()\n",
    "    print(f\"Current Q Learning model has {len(qLearningPlayer)} states\")\n",
    "    \n",
    "    MinMaxLetter = 2  # MinMax Player\n",
    "    QLearningLetter = 1  \n",
    "\n",
    "    for _ in range(games):\n",
    "        c4Game = original_board(rows, columns)\n",
    "        \n",
    "        # Determine who plays first by random choice\n",
    "        MinMaxPlaysFirst = random.choice([True, False])\n",
    "        \n",
    "        # Playing a game of Connect4\n",
    "        winner = play_connect4_game(MinMaxPlaysFirst, qLearningPlayer, MinMaxLetter, QLearningLetter, c4Game, depth=8, epsilon=0.1)\n",
    "        if winner == 'QLearningWon':\n",
    "            QLearningWin += 1\n",
    "        elif winner == 'MinMaxWon':\n",
    "            MinMaxWin += 1\n",
    "        else:\n",
    "            Draw += 1\n",
    "    \n",
    "    print(\"Results:\")\n",
    "    print(f\"MinMax wins: {MinMaxWin}\")\n",
    "    print(f\"QLearning wins: {QLearningWin}\")\n",
    "    print(f\"Draws: {Draw}\")\n",
    "\n",
    "\n",
    "games = 5\n",
    "simulate_games(games, 6, 7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Q Learning model has 87890237 states\n",
    "Results:\n",
    "MinMax wins: 143\n",
    "QLearning wins: 46\n",
    "Draws: 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Q Learning model has 87890237 states\n",
      "Results:\n",
      "MinMax wins: 139\n",
      "QLearning wins: 49\n",
      "Draws: 12\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def simulate_games_minmax(games, rows, columns):\n",
    "    MinMaxWin = QLearningWin = Draw = 0\n",
    "    qLearningPlayer = load_q_model()\n",
    "    print(f\"Current Q Learning model has {len(qLearningPlayer)} states\")\n",
    "    \n",
    "    MinMaxLetter = 2  \n",
    "    QLearningLetter = 1  \n",
    "\n",
    "    for _ in range(games):\n",
    "        c4Game = original_board(rows, columns)\n",
    "        \n",
    "        # MinMax always plays first\n",
    "        MinMaxPlaysFirst = True\n",
    "        \n",
    "        \n",
    "        winner = play_connect4_game(MinMaxPlaysFirst, qLearningPlayer, MinMaxLetter, QLearningLetter, c4Game, depth=8, epsilon=0.1)\n",
    "        if winner == 'QLearningWon':\n",
    "            QLearningWin += 1\n",
    "        elif winner == 'MinMaxWon':\n",
    "            MinMaxWin += 1\n",
    "        else:\n",
    "            Draw += 1\n",
    "    \n",
    "    print(\"Results:\")\n",
    "    print(f\"MinMax wins: {MinMaxWin}\")\n",
    "    print(f\"QLearning wins: {QLearningWin}\")\n",
    "    print(f\"Draws: {Draw}\")\n",
    "\n",
    "\n",
    "games = 200\n",
    "simulate_games_minmax(games, 6, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Q Learning model has 87890237 states\n",
      "Results:\n",
      "MinMax wins: 145\n",
      "QLearning wins: 47\n",
      "Draws: 8\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def simulate_games(games, rows, columns):\n",
    "    MinMaxWin = QLearningWin = Draw = 0\n",
    "    qLearningPlayer = load_q_model()\n",
    "    print(f\"Current Q Learning model has {len(qLearningPlayer)} states\")\n",
    "    \n",
    "    MinMaxLetter = 2  \n",
    "    QLearningLetter = 1  \n",
    "\n",
    "    for _ in range(games):\n",
    "        c4Game = original_board(rows, columns)\n",
    "        \n",
    "        # QLearning always plays first\n",
    "        MinMaxPlaysFirst = False\n",
    "        \n",
    "        \n",
    "        winner = play_connect4_game(MinMaxPlaysFirst, qLearningPlayer, MinMaxLetter, QLearningLetter, c4Game, depth=8, epsilon=0.1)\n",
    "        if winner == 'QLearningWon':\n",
    "            QLearningWin += 1\n",
    "        elif winner == 'MinMaxWon':\n",
    "            MinMaxWin += 1\n",
    "        else:\n",
    "            Draw += 1\n",
    "    \n",
    "    print(\"Results:\")\n",
    "    print(f\"MinMax wins: {MinMaxWin}\")\n",
    "    print(f\"QLearning wins: {QLearningWin}\")\n",
    "    print(f\"Draws: {Draw}\")\n",
    "\n",
    "\n",
    "games = 200\n",
    "simulate_games(games, 6, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
