{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def save_q_model(ql_states, file_path=\"Connect4QLearningModel.pickle\"):\\n    with open(file_path, \"wb\") as file:\\n        pickle.dump(ql_states, file)\\n\\ndef train_q_model():\\n    ql_states = {}\\n    ql_win = si_agent_win = draw = 0\\n    ql_learning_letter = 1\\n    si_agent_letter = 2\\n    total_episodes = 1000000\\n    \\n    for episode in range(total_episodes):\\n        connect4board = original_board()\\n        epsilon = 1.0\\n\\n        while True:\\n            ql_possible_positions = get_correct_turn(connect4board)\\n\\n            if len(ql_possible_positions) == 0:\\n                break\\n\\n            ql_chosen_column = get_best_action_from_q_values(ql_states, connect4board, ql_possible_positions, epsilon)\\n            ql_chosen_row = get_next_row(connect4board, ql_chosen_column)\\n            connect4board[ql_chosen_row][ql_chosen_column] = ql_learning_letter\\n\\n            if val_success(connect4board, ql_learning_letter):\\n                ql_win += 1\\n                update_q_model(ql_states, connect4board, ql_chosen_column, 1, connect4board, [])\\n                break\\n            elif val_success(connect4board, si_agent_letter):\\n                si_agent_win += 1\\n                update_q_model(ql_states, connect4board, ql_chosen_column, -1, connect4board, [])\\n                break\\n            elif len(get_correct_turn(connect4board)) == 0:\\n                draw += 1\\n                update_q_model(ql_states, connect4board, ql_chosen_column, 0, connect4board, [])\\n                break\\n            else:\\n                update_q_model(ql_states, connect4board, ql_chosen_column, 0, connect4board, get_correct_turn(connect4board))\\n\\n            si_agent_chosen_row, si_agent_chosen_column = si_agent_turn(connect4board, connect4board, si_agent_letter, ql_learning_letter)\\n            connect4board[si_agent_chosen_row][si_agent_chosen_column] = si_agent_letter\\n\\n            if val_success(connect4board, ql_learning_letter):\\n                ql_win += 1\\n                update_q_model(ql_states, connect4board, si_agent_chosen_column, 1, connect4board, [])\\n                break\\n            elif val_success(connect4board, si_agent_letter):\\n                si_agent_win += 1\\n                update_q_model(ql_states, connect4board, si_agent_chosen_column, -1, connect4board, [])\\n                break\\n            elif len(get_correct_turn(connect4board)) == 0:\\n                draw += 1\\n                update_q_model(ql_states, connect4board, si_agent_chosen_column, 0, connect4board, [])\\n                break\\n            else:\\n                update_q_model(ql_states, connect4board, si_agent_chosen_column, 0, connect4board, get_correct_turn(connect4board))\\n\\n            epsilon = update_epsilon(epsilon)\\n\\n        if episode % 1000 == 0:\\n            print(f\"Episode {episode}: QLearning wins - {ql_win}, SI Agent wins - {si_agent_win}, Draws - {draw}\")\\n\\n    return ql_states, ql_win, si_agent_win, draw, total_episodes\\n\\nql_states, ql_win, si_agent_win, draw, total_episodes = train_q_model()\\n\\nprint(f\"QLearning wins: {ql_win}\")\\nprint(f\"SI Agent wins: {si_agent_win}\")\\nprint(f\"Draws: {draw}\")\\nprint(f\"Total Episodes: {total_episodes}\")\\n\\nsave_q_model(ql_states)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "def original_board(rows=6, columns=7):\n",
    "    return np.zeros((rows, columns))\n",
    "\n",
    "def val_turn(connect4board, column):\n",
    "    return connect4board[len(connect4board)-1][column] == 0\n",
    "\n",
    "def get_next_row(connect4board, column):\n",
    "    return next((row for row in range(len(connect4board)) if connect4board[row][column] == 0), None)\n",
    "\n",
    "def get_correct_turn(connect4board):\n",
    "    return [column for column in range(connect4board.shape[1]) if val_turn(connect4board, column)]\n",
    "\n",
    "def get_next_pos(connect4board, letter):\n",
    "    rows, cols = connect4board.shape\n",
    "    for row, row_vals in enumerate(connect4board):\n",
    "        for col, col_val in enumerate(row_vals[:-3]):\n",
    "            if all(elem == letter for elem in row_vals[col:col+4]):\n",
    "                return row, col\n",
    "        for col, col_vals in zip(range(cols), (connect4board[r][col] for r in range(row, min(row+4, rows)))):\n",
    "            if all(elem == letter for elem in col_vals):\n",
    "                return row, col\n",
    "        for col, col_vals in enumerate(row_vals[:-3]):\n",
    "            if row < rows-3 and col < cols-3:\n",
    "                diag_vals = [connect4board[row+i][col+i] for i in range(4)]\n",
    "                if all(elem == letter for elem in diag_vals):\n",
    "                    return row, col\n",
    "        for col, col_vals in enumerate(row_vals[:-3]):\n",
    "            if row >= 3 and col < cols-3:\n",
    "                diag_vals = [connect4board[row-i][col+i] for i in range(4)]\n",
    "                if all(elem == letter for elem in diag_vals):\n",
    "                    return row, col\n",
    "    else:\n",
    "        return -1, -1\n",
    "\n",
    "def val_success(connect4board, letter):\n",
    "    rows, cols = connect4board.shape\n",
    "    for row in range(rows):\n",
    "        for col in range(cols - 3):\n",
    "            if all(connect4board[row][col + i] == letter for i in range(4)):\n",
    "                return True\n",
    "\n",
    "    for row in range(rows - 3):\n",
    "        for col in range(cols):\n",
    "            if all(connect4board[row + i][col] == letter for i in range(4)):\n",
    "                return True\n",
    "\n",
    "    for row in range(rows - 3):\n",
    "        for col in range(cols - 3):\n",
    "            if all(connect4board[row + i][col + i] == letter for i in range(4)):\n",
    "                return True\n",
    "\n",
    "    for row in range(3, rows):\n",
    "        for col in range(cols - 3):\n",
    "            if all(connect4board[row - i][col + i] == letter for i in range(4)):\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def first_turn():\n",
    "    choices = [1, 2]\n",
    "    return random.choice(choices)\n",
    "\n",
    "def val_final_turn(connect4board, si_agent_letter, minmax_letter):\n",
    "    return any(val_success(connect4board, letter) for letter in (si_agent_letter, minmax_letter)) or not get_correct_turn(connect4board)\n",
    "\n",
    "def si_agent_turn( connect4board, si_agent_letter, minmax_letter):\n",
    "    if val_final_turn(connect4board, si_agent_letter, minmax_letter):\n",
    "        siagent_row, siagent_col = get_next_pos(connect4board, si_agent_letter)\n",
    "        if siagent_row != -1:\n",
    "            return siagent_row, siagent_col\n",
    "        else:\n",
    "            minmax_row, minmax_col = get_next_pos(connect4board, minmax_letter)\n",
    "            if minmax_row != -1:\n",
    "                return minmax_row, minmax_col\n",
    "            else:\n",
    "                possible_positions = get_correct_turn(connect4board)\n",
    "                random_row = get_next_row(connect4board, random.choice(possible_positions))\n",
    "                random_col = random.choice(possible_positions)\n",
    "                return random_row, random_col\n",
    "    else:\n",
    "        possible_positions = get_correct_turn(connect4board)\n",
    "        random_row = get_next_row(connect4board, random.choice(possible_positions)) \n",
    "        random_col = random.choice(possible_positions)\n",
    "\n",
    "        return random_row, random_col\n",
    "\n",
    "def get_pos(positions):\n",
    "    return int(''.join([str(int(position)) for position in positions.flatten()]))\n",
    "\n",
    "def get_q_values_for_action(ql_states, current_connect4board, current_position):\n",
    "    position = get_pos(current_connect4board)\n",
    "    if position not in ql_states:\n",
    "        ql_states[(position, current_position)] = 0\n",
    "    return ql_states[(position, current_position)]\n",
    "\n",
    "def get_best_action_from_q_values(ql_states, current_connect4board, possible_positions, epsilon):\n",
    "    return random.choice(possible_positions) if random.random() < epsilon else max([(get_q_values_for_action(ql_states, current_connect4board, position), position) for position in possible_positions], key=lambda x: x[0])[1]\n",
    "\n",
    "def update_q_model(ql_states, current_connect4board, current_position, reward, successive_connect4board, possible_positions, alpha=0.1, gamma=0.99):\n",
    "    best_q_value = max([get_q_values_for_action(ql_states, successive_connect4board, next_position) for next_position in possible_positions], default=0)\n",
    "    optimised_q_value = get_q_values_for_action(ql_states, current_connect4board, current_position) + alpha * ((reward + gamma * best_q_value) - get_q_values_for_action(ql_states, current_connect4board, current_position))\n",
    "    position = get_pos(current_connect4board)\n",
    "    ql_states[(position, current_position)] = optimised_q_value\n",
    "\n",
    "def update_epsilon(epsilon):\n",
    "    return max(epsilon * 0.999, 0.1)\n",
    "\n",
    "'''def save_q_model(ql_states, file_path=\"Connect4QLModel.pickle\"):\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        pickle.dump(ql_states, file)\n",
    "\n",
    "def train_q_model():\n",
    "    ql_states = {}\n",
    "    ql_win = si_agent_win = draw = 0\n",
    "    ql_learning_letter = 1\n",
    "    si_agent_letter = 2\n",
    "    total_episodes = 1000000\n",
    "    \n",
    "    for episode in range(total_episodes):\n",
    "        connect4board = original_board()\n",
    "        epsilon = 1.0\n",
    "\n",
    "        while True:\n",
    "            ql_possible_positions = get_correct_turn(connect4board)\n",
    "\n",
    "            if len(ql_possible_positions) == 0:\n",
    "                break\n",
    "\n",
    "            ql_chosen_column = get_best_action_from_q_values(ql_states, connect4board, ql_possible_positions, epsilon)\n",
    "            ql_chosen_row = get_next_row(connect4board, ql_chosen_column)\n",
    "            connect4board[ql_chosen_row][ql_chosen_column] = ql_learning_letter\n",
    "\n",
    "            if val_success(connect4board, ql_learning_letter):\n",
    "                ql_win += 1\n",
    "                update_q_model(ql_states, connect4board, ql_chosen_column, 1, connect4board, [])\n",
    "                break\n",
    "            elif val_success(connect4board, si_agent_letter):\n",
    "                si_agent_win += 1\n",
    "                update_q_model(ql_states, connect4board, ql_chosen_column, -1, connect4board, [])\n",
    "                break\n",
    "            elif len(get_correct_turn(connect4board)) == 0:\n",
    "                draw += 1\n",
    "                update_q_model(ql_states, connect4board, ql_chosen_column, 0, connect4board, [])\n",
    "                break\n",
    "            else:\n",
    "                update_q_model(ql_states, connect4board, ql_chosen_column, 0, connect4board, get_correct_turn(connect4board))\n",
    "\n",
    "            si_agent_chosen_row, si_agent_chosen_column = si_agent_turn(connect4board, connect4board, si_agent_letter, ql_learning_letter)\n",
    "            connect4board[si_agent_chosen_row][si_agent_chosen_column] = si_agent_letter\n",
    "\n",
    "            if val_success(connect4board, ql_learning_letter):\n",
    "                ql_win += 1\n",
    "                update_q_model(ql_states, connect4board, si_agent_chosen_column, 1, connect4board, [])\n",
    "                break\n",
    "            elif val_success(connect4board, si_agent_letter):\n",
    "                si_agent_win += 1\n",
    "                update_q_model(ql_states, connect4board, si_agent_chosen_column, -1, connect4board, [])\n",
    "                break\n",
    "            elif len(get_correct_turn(connect4board)) == 0:\n",
    "                draw += 1\n",
    "                update_q_model(ql_states, connect4board, si_agent_chosen_column, 0, connect4board, [])\n",
    "                break\n",
    "            else:\n",
    "                update_q_model(ql_states, connect4board, si_agent_chosen_column, 0, connect4board, get_correct_turn(connect4board))\n",
    "\n",
    "            epsilon = update_epsilon(epsilon)\n",
    "\n",
    "        if episode % 1000 == 0:\n",
    "            print(f\"Episode {episode}: QLearning wins - {ql_win}, SI Agent wins - {si_agent_win}, Draws - {draw}\")\n",
    "\n",
    "    return ql_states, ql_win, si_agent_win, draw, total_episodes\n",
    "\n",
    "ql_states, ql_win, si_agent_win, draw, total_episodes = train_q_model()\n",
    "\n",
    "print(f\"QLearning wins: {ql_win}\")\n",
    "print(f\"SI Agent wins: {si_agent_win}\")\n",
    "print(f\"Draws: {draw}\")\n",
    "print(f\"Total Episodes: {total_episodes}\")\n",
    "\n",
    "save_q_model(ql_states)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def load_q_learning_model(file_path=\"Connect4QLModel.pickle\"):\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            ql_states = pickle.load(file)\n",
    "            return ql_states\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Could not find the Q-learning model file.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def play_connect4(SIAgent_plays_first, connect4_connect4board, si_agent_turn, get_correct_turn, val_success):\n",
    "    QLearningLetter = 1\n",
    "    SIAgentLetter = 2\n",
    "\n",
    "    while True:\n",
    "        if SIAgent_plays_first:\n",
    "            \n",
    "            SIAgentPossible_Positions = get_correct_turn(connect4_connect4board)\n",
    "\n",
    "            if len(SIAgentPossible_Positions) == 0:\n",
    "                return \"Draw\"\n",
    "\n",
    "            SIAgent_chosen_row, SIAgent_chosen_column = si_agent_turn(connect4_connect4board, SIAgentLetter, QLearningLetter)\n",
    "            connect4_connect4board[SIAgent_chosen_row][SIAgent_chosen_column] = SIAgentLetter\n",
    "            \n",
    "            if val_success(connect4_connect4board, SIAgentLetter): \n",
    "                return \"SIAgentWon\"\n",
    "\n",
    "            if val_success(connect4_connect4board, QLearningLetter):\n",
    "                return \"QLearningWon\"\n",
    "\n",
    "            if len(get_correct_turn(connect4_connect4board)) == 0:\n",
    "                return \"Draw\"\n",
    "            \n",
    "            QLearningPossible_Positions = get_correct_turn(connect4_connect4board)\n",
    "                \n",
    "            if len(QLearningPossible_Positions) == 0:\n",
    "                return \"Draw\"\n",
    "                \n",
    "            QLearning_chosen_column = random.choice(QLearningPossible_Positions)\n",
    "            QLearning_chosen_row = get_next_row(connect4_connect4board, QLearning_chosen_column)\n",
    "            connect4_connect4board[QLearning_chosen_row][QLearning_chosen_column] = QLearningLetter\n",
    "            \n",
    "            if val_success(connect4_connect4board, SIAgentLetter): \n",
    "                return \"SIAgentWon\"\n",
    "\n",
    "            if val_success(connect4_connect4board, QLearningLetter):\n",
    "                return \"QLearningWon\"\n",
    "\n",
    "            if len(get_correct_turn(connect4_connect4board)) == 0:\n",
    "                return \"Draw\"\n",
    "            \n",
    "        else:\n",
    "            QLearningPossible_Positions = get_correct_turn(connect4_connect4board)\n",
    "                \n",
    "            if len(QLearningPossible_Positions) == 0:\n",
    "                return \"Draw\"\n",
    "                \n",
    "            QLearning_chosen_column = random.choice(QLearningPossible_Positions)\n",
    "            QLearning_chosen_row = get_next_row(connect4_connect4board, QLearning_chosen_column)\n",
    "            connect4_connect4board[QLearning_chosen_row][QLearning_chosen_column] = QLearningLetter\n",
    "            \n",
    "            if val_success(connect4_connect4board, SIAgentLetter): \n",
    "                return \"SIAgentWon\"\n",
    "\n",
    "            if val_success(connect4_connect4board, QLearningLetter):\n",
    "                return \"QLearningWon\"\n",
    "\n",
    "            if len(get_correct_turn(connect4_connect4board)) == 0:\n",
    "                return \"Draw\"\n",
    "\n",
    "\n",
    "            SIAgentPossible_Positions = get_correct_turn(connect4_connect4board)\n",
    "\n",
    "            if len(SIAgentPossible_Positions) == 0:\n",
    "                return \"Draw\"\n",
    "\n",
    "            SIAgent_chosen_row, SIAgent_chosen_column = si_agent_turn(connect4_connect4board, SIAgentLetter, QLearningLetter)\n",
    "            connect4_connect4board[SIAgent_chosen_row][SIAgent_chosen_column] = SIAgentLetter\n",
    "            \n",
    "            if val_success(connect4_connect4board, SIAgentLetter): \n",
    "                return \"SIAgentWon\"\n",
    "\n",
    "            if val_success(connect4_connect4board, QLearningLetter):\n",
    "                return \"QLearningWon\"\n",
    "\n",
    "            if len(get_correct_turn(connect4_connect4board)) == 0:\n",
    "                return \"Draw\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Q Learning model has 87890237 states\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "games = 5\n",
    "SIAgentWin = QLearningWin = Draw = 0\n",
    "\n",
    "si_agent = si_agent_turn\n",
    "ql_states = load_q_learning_model()\n",
    "\n",
    "print(f\"Current Q Learning model has {len(ql_states)} states\")\n",
    "\n",
    "for _ in (range(games)):\n",
    "    connect4_connect4board = original_board()\n",
    "    \n",
    "    SIAgent_plays_first = False\n",
    "    if first_turn() == 1:\n",
    "        SIAgent_plays_first = True\n",
    "    else:\n",
    "        SIAgent_plays_first = False\n",
    "    \n",
    "    winner = play_connect4(SIAgent_plays_first, connect4_connect4board, si_agent_turn, get_correct_turn, val_success)\n",
    "\n",
    "    if winner == 'QLearningWon':\n",
    "        QLearningWin += 1\n",
    "    elif winner == 'SIAgentWon':\n",
    "        SIAgentWin += 1\n",
    "    else:\n",
    "        Draw += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Semi-Intelligent Agent wins: 2\n",
      "Q-Learning Agent wins: 3\n",
      "Draws: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Results:\")\n",
    "print(f\"Semi-Intelligent Agent wins: {SIAgentWin}\")\n",
    "print(f\"Q-Learning Agent wins: {QLearningWin}\")\n",
    "print(f\"Draws: {Draw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "Semi-Intelligent Agent wins: 698\n",
    "Q-Learning Agent wins: 1276\n",
    "Draws: 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Q Learning model has 87890237 states\n",
      "Results:\n",
      "Semi-Intelligent Agent wins: 645\n",
      "Q-Learning Agent wins: 1326\n",
      "Draws: 29\n"
     ]
    }
   ],
   "source": [
    "games = 2000\n",
    "SIAgentWin = QLearningWin = Draw = 0\n",
    "\n",
    "si_agent = si_agent_turn\n",
    "ql_states = load_q_learning_model()\n",
    "\n",
    "print(f\"Current Q Learning model has {len(ql_states)} states\")\n",
    "\n",
    "# Set Q-Learning agent to make the first move\n",
    "SIAgent_plays_first = False\n",
    "\n",
    "for _ in range(games):\n",
    "    connect4_connect4board = original_board()\n",
    "    \n",
    "    \n",
    "    winner = play_connect4(SIAgent_plays_first, connect4_connect4board, si_agent_turn, get_correct_turn, val_success)\n",
    "\n",
    "    if winner == 'QLearningWon':\n",
    "        QLearningWin += 1\n",
    "    elif winner == 'SIAgentWon':\n",
    "        SIAgentWin += 1\n",
    "    else:\n",
    "        Draw += 1\n",
    "\n",
    "print(\"Results:\")\n",
    "print(f\"Semi-Intelligent Agent wins: {SIAgentWin}\")\n",
    "print(f\"Q-Learning Agent wins: {QLearningWin}\")\n",
    "print(f\"Draws: {Draw}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Q Learning model has 87890237 states\n",
      "Results:\n",
      "Semi-Intelligent Agent wins: 774\n",
      "Q-Learning Agent wins: 1198\n",
      "Draws: 28\n"
     ]
    }
   ],
   "source": [
    "games = 2000\n",
    "SIAgentWin = QLearningWin = Draw = 0\n",
    "\n",
    "si_agent = si_agent_turn\n",
    "ql_states = load_q_learning_model()\n",
    "\n",
    "print(f\"Current Q Learning model has {len(ql_states)} states\")\n",
    "\n",
    "# Set semi-intelligent agent to make the first move\n",
    "SIAgent_plays_first = True\n",
    "\n",
    "for _ in range(games):\n",
    "    connect4_connect4board = original_board()\n",
    "    \n",
    "    \n",
    "    winner = play_connect4(SIAgent_plays_first, connect4_connect4board, si_agent_turn, get_correct_turn, val_success)\n",
    "\n",
    "    if winner == 'QLearningWon':\n",
    "        QLearningWin += 1\n",
    "    elif winner == 'SIAgentWon':\n",
    "        SIAgentWin += 1\n",
    "    else:\n",
    "        Draw += 1\n",
    "\n",
    "print(\"Results:\")\n",
    "print(f\"Semi-Intelligent Agent wins: {SIAgentWin}\")\n",
    "print(f\"Q-Learning Agent wins: {QLearningWin}\")\n",
    "print(f\"Draws: {Draw}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
